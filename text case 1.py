# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OdS2rl09tQUd5Ci7ctwFxKQct0BDe3ho
"""

from keras.models import Sequential
from keras.layers import Dense
import numpy as np

# XOR Data
X = np.array([[0,0], [0,1], [1,0], [1,1]])
Y = np.array([[0], [1], [1], [0]])

# Model: Single-Layer Perceptron
model = Sequential()
model.add(Dense(1, input_dim=2, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train
model.fit(X, Y, epochs=1000, verbose=0)

# Predictions & Remarks
predictions = model.predict(X)
print("\n--- Test 2: Single-Layer Perceptron (Observation) ---")
print("Input\tPredicted\tExpected\tRemark")
for i, p in enumerate(predictions):
    predicted_binary = 1 if p[0] >= 0.5 else 0
    remark = "Correct" if predicted_binary == Y[i][0] else "May fail"
    print(f"{X[i]}\t{predicted_binary} ({p[0]:.4f})\t{Y[i][0]}\t\t{remark}")

from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import matplotlib.pyplot as plt

# XOR Data
X = np.array([[0,0], [0,1], [1,0], [1,1]])
Y = np.array([[0], [1], [1], [0]])

# Model: Multi-Layer Perceptron
model = Sequential()
model.add(Dense(4, input_dim=2, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train
history = model.fit(X, Y, epochs=1000, verbose=0)

# Evaluate
loss, acc = model.evaluate(X, Y, verbose=0)
print("\n--- Test 1: MLP for XOR ---")
print("Accuracy:", acc)

# Predictions
predictions = model.predict(X)
for i, p in enumerate(predictions):
    print(f"Input: {X[i]} -> Predicted: {p[0]:.4f}, Expected: {Y[i][0]}")

# Plot loss
plt.plot(history.history['loss'])
plt.title('Model Loss (MLP for XOR)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.show()
v

